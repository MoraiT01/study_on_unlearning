{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Networks\n",
    "\n",
    "In this notebook, we want to compare different network to each other.\n",
    "This one contains\n",
    "\n",
    "- Untrained Model\n",
    "- Trained Model\n",
    "- Machine Unlearning Algorithm of your chosing\n",
    "\n",
    "There will be a notebook for every approx. MU algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# from helper import get_model TODO Muss Ã¼berarbeitet werden\n",
    "from mlp_dataclass import MNIST_CostumDataset, TwoLayerPerceptron, ConvNet\n",
    "from training import main, train_n_models\n",
    "from helper import load_models_dict\n",
    "\n",
    "USED_DATASET = \"mnist\"\n",
    "# OUT OF: [\"mnist\", \"cmnist\", \"fashion_mnist\"]\n",
    "\n",
    "ALLREADY_TRAINED = False\n",
    "\n",
    "all_data = MNIST_CostumDataset(\n",
    "    sample_mode=\"all\",\n",
    "    train= True,\n",
    "    test = True,\n",
    "    dataset_name = USED_DATASET,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "unlearned_data = MNIST_CostumDataset(\n",
    "    sample_mode=\"only_erased\",\n",
    "    train= True,\n",
    "    test = False,\n",
    "    classes=[\"7\"],\n",
    "    dataset_name = USED_DATASET,\n",
    "    download=True,\n",
    ")\n",
    "len(unlearned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample(path:str):\n",
    "    \"\"\"preps sample to pass to model, transforms to tensor, reshape to 784, shaping it as batch\"\"\"\n",
    "    sample = Image.open(path).convert(\"L\")\n",
    "    sample = torch.Tensor(np.array(sample)).reshape(784)\n",
    "    \n",
    "    return sample.unsqueeze(0)\n",
    "\n",
    "def show_sample(sample:torch.Tensor):\n",
    "    \"\"\"Converts the sample to a numpy array and reshapes it to a 28x28 image\"\"\"\n",
    "    sample = sample.reshape(28, 28)\n",
    "    sample = sample.numpy()\n",
    "    sample = Image.fromarray(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USED_DATASET in [\"mnist\", \"fashion_mnist\"]:\n",
    "    untrained_showcase_all= TwoLayerPerceptron()\n",
    "if USED_DATASET in [\"cmnist\"]:\n",
    "    untrained_showcase_all = ConvNet()\n",
    "name = str(untrained_showcase_all)\n",
    "untrained_showcase_all.load_state_dict(\n",
    "    torch.load(\n",
    "        f=f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}untrained{os.sep}{name}_showcase_untrained\",\n",
    "        weights_only=True\n",
    "        )\n",
    "    )\n",
    "untrained_ms = load_models_dict(f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}untrained{os.sep}ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USED_DATASET in [\"mnist\", \"fashion_mnist\"]:\n",
    "    trained_showcase_all= TwoLayerPerceptron()\n",
    "if USED_DATASET in [\"cmnist\"]:\n",
    "    trained_showcase_all = ConvNet()\n",
    "name = str(trained_showcase_all)\n",
    "trained_showcase_all.load_state_dict(\n",
    "    torch.load(\n",
    "        f=f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}all{os.sep}{name}_b_trained_showcase\",\n",
    "        weights_only=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ms = load_models_dict(path=f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}all{os.sep}test_ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Yet Effective Machine Unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unlearning import unlearn_n_models, ...\n",
    "from training import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single model first\n",
    "if not ALLREADY_TRAINED:\n",
    "    sga = ...(\n",
    "        model=trained_showcase_all,\n",
    "        unlearned_data=unlearned_data,\n",
    "        dataset_name=USED_DATASET,\n",
    "    )\n",
    "    mu_showcase = sga.unlearn()\n",
    "    save_model(mu_showcase, name=\"mu_showcase\", path=f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}...\", logs=False)\n",
    "else:\n",
    "    if USED_DATASET in [\"mnist\", \"fashion_mnist\"]:\n",
    "        mu_showcase= TwoLayerPerceptron()\n",
    "    if USED_DATASET in [\"cmnist\"]:\n",
    "        mu_showcase= ConvNet()\n",
    "    name = str(mu_showcase)\n",
    "    mu_showcase.load_state_dict(\n",
    "        torch.load(\n",
    "            f=f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}...{os.sep}{name}_mu_showcase\",\n",
    "            weights_only=True\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ALLREADY_TRAINED:\n",
    "    mu_ms = unlearn_n_models(\n",
    "        models=trained_ms,\n",
    "        unlearned_data=unlearned_data,\n",
    "        dataset_name=USED_DATASET,\n",
    "        which_unlearning=\"...\",\n",
    "        logs=True,\n",
    "    )\n",
    "    for i, model in mu_ms.items():\n",
    "        save_model(model=model, name=f\"{i}_mu\", path=f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}...{os.sep}test_ensemble\", logs=False)\n",
    "\n",
    "else:\n",
    "    mu_ms = load_models_dict(path=f\"..{os.sep}data{os.sep}models{os.sep}{USED_DATASET}{os.sep}...{os.sep}test_ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Norm\n",
    "\n",
    "Compare how the different models are from each other using the L2 Norm, comparing every parameter with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import model_l2_norm_difference, calc_mutlimodel_metric_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can luckily cut down on some calculations, since the **L2-Norm** is symmetrical\n",
    "\n",
    "#### Unlearn to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...trained model\n",
    "a11 = calc_mutlimodel_metric_average(untrained_ms, trained_ms, metric=\"l2_norm\")\n",
    "a11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...exact model\n",
    "a12 = calc_mutlimodel_metric_average(untrained_ms, mu_ms, metric=\"l2_norm\")\n",
    "a12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...untrained model\n",
    "a21 = calc_mutlimodel_metric_average(trained_ms, mu_ms, metric=\"l2_norm\")\n",
    "a21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL-Divergence\n",
    "\n",
    "Used to compare the difference between distribution, but may also be used to compare models by their predicted target distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import kl_divergence_between_models, calc_mutlimodel_metric_average\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=unlearned_data,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlearned to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mutlimodel_metric_average(\n",
    "    modeltype1=untrained_ms,\n",
    "    modeltype2=mu_ms,\n",
    "    testing_loader=dataloader,\n",
    "    metric=\"kl_div\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mutlimodel_metric_average(\n",
    "    modeltype1=trained_ms,\n",
    "    modeltype2=mu_ms,\n",
    "    testing_loader=dataloader,\n",
    "    metric=\"kl_div\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mutlimodel_metric_average(\n",
    "    modeltype1=trained_ms,\n",
    "    modeltype2=untrained_ms,\n",
    "    testing_loader=dataloader,\n",
    "    metric=\"kl_div\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mutlimodel_metric_average(\n",
    "    modeltype1=trained_ms,\n",
    "    modeltype2=mu_ms,\n",
    "    testing_loader=dataloader,\n",
    "    metric=\"kl_div\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MU to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mutlimodel_metric_average(\n",
    "    modeltype1=mu_ms,\n",
    "    modeltype2=untrained_ms,\n",
    "    testing_loader=dataloader,\n",
    "    metric=\"kl_div\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mutlimodel_metric_average(\n",
    "    modeltype1=mu_ms,\n",
    "    modeltype2=trained_ms,\n",
    "    testing_loader=dataloader,\n",
    "    metric=\"kl_div\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "- $D_{Gesamt}$\n",
    "- $D_{Erased}$\n",
    "- $D_{Remain}$\n",
    "- $D_{Accuracy Per Class}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import boxplotting_multimodel_eval\n",
    "\n",
    "accs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see what metrics each model has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take like 80minutes\n",
    "accs[\"mu_ms\"] = boxplotting_multimodel_eval(mu_ms, dataset_name=USED_DATASET, evaluation=\"accuracy\", logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[\"mu_ms\"] = boxplotting_multimodel_eval(mu_ms, dataset_name=USED_DATASET, evaluation=\"loss\", logs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach.conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
