{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Networks\n",
    "\n",
    "In this notebook, we want to compare different network to each other.\n",
    "We will start of with...\n",
    "\n",
    "- Untrained Model\n",
    "- Trained Model\n",
    "- Trained Model (Exact Unlearning)*$^1$\n",
    "\n",
    "All these model should serve as comparison point for approximate MU Algorithms, which we want to try out\n",
    "\n",
    "*$^1$ Exact Unlearning: refers to an complete retraining of the Model, without the samples which we want to unlearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morit\\miniconda3\\envs\\bach.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from helper import get_model\n",
    "from mlp_dataclass import MNIST_CostumDataset, TwoLayerPerceptron\n",
    "from training import main\n",
    "\n",
    "EXAMPLE = f\"..{os.sep}data{os.sep}mnist_dataset{os.sep}7e{os.sep}test_0.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample(path:str):\n",
    "    \"\"\"preps sample to pass to model, transforms to tensor, reshape to 784, shaping it as batch\"\"\"\n",
    "    sample = Image.open(path).convert(\"L\")\n",
    "    sample = torch.Tensor(np.array(sample)).reshape(784)\n",
    "    \n",
    "    return sample.unsqueeze(0)\n",
    "\n",
    "def show_sample(sample:torch.Tensor):\n",
    "    \"\"\"Converts the sample to a numpy array and reshapes it to a 28x28 image\"\"\"\n",
    "    sample = sample.reshape(28, 28)\n",
    "    sample = sample.numpy()\n",
    "    sample = Image.fromarray(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample(prepare_sample(EXAMPLE)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untrained Model\n",
    "\n",
    "We want to include an untrained model as a pour reference point.\n",
    "\n",
    "Later, we will compare the differently trained (and untrained) models on different metrics. We are thinking, that the **untrained model should always be the furthest neighbor** and see if thats true. Also out of pur curiosity, how do the models compare according to the found metrics to the untrained model.\n",
    "\n",
    "It could be interesting to see, if the unlearned models tend to be more similar to the \"Exact MU Model\" or to the \"Untrained Model\"\n",
    "\n",
    "The \"Trained Model\"´s and \"Exact Model\"´s starting point is the \"Untrained Model\". That means all models can be traced back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untrained_model = TwoLayerPerceptron(input_dim=784, output_dim=10)\n",
    "\n",
    "# torch.save(untrained_model.state_dict(), f\"..{os.sep}data{os.sep}models{os.sep}untrained_model\")\n",
    "\n",
    "# print(\"Shape of Tenosr: \", prepare_sample(EXAMPLE).shape)\n",
    "# untrained_model(prepare_sample(EXAMPLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoLayerPerceptron(\n",
       "  (fc1): Linear(in_features=784, out_features=800, bias=True)\n",
       "  (fc3): Linear(in_features=800, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained_model = TwoLayerPerceptron(input_dim=784, output_dim=10)\n",
    "untrained_model.load_state_dict(torch.load(f\"..{os.sep}data{os.sep}models{os.sep}untrained_model\", weights_only=True))\n",
    "untrained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tenosr:  torch.Size([1, 784])\n",
      "tensor([[-1.4305e-06, -3.3952e+01, -4.6039e+01, -1.4157e+01, -1.8464e+01,\n",
      "         -3.3265e+01, -4.0250e+01, -4.1240e+01, -1.4187e+01, -4.3337e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-1.4305e-06], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of Tenosr: \", prepare_sample(EXAMPLE).shape)\n",
    "print(untrained_model(prepare_sample(EXAMPLE)))\n",
    "torch.max(untrained_model(prepare_sample(EXAMPLE)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Model\n",
    "\n",
    "This model will be the starting point for all MU algorithms. The more it is important that it does not change throughout the experiments, otherwise we need to run everything again.\n",
    "\n",
    "Notes Regarding the Dataloader: We included Up-/Downsampling. There is a counter in the Dataset class, which controls, which class is next to provide a sample. From the available pool a sample will be chosen at random.\n",
    "\n",
    "Reason: The amount of available samples should not influence the performance of the model on certain classes.\n",
    "\n",
    "Regarding the samples for the class \"7\": There are more samples of sevens without a middle line than ones with.\n",
    "\n",
    "Ratio: \n",
    "- 6268 (train: 5385, test: 883)\n",
    "- 1025 (train: 880,  test: 145)\n",
    "\n",
    "Should there be concerns regarding that the bigger part of the sevens (without middle line) will be unlearning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main(\n",
    "#     new_name=\"trained_model\",\n",
    "#     model=copy.deepcopy(untrained_model),\n",
    "#     sampling_mode=\"all\",\n",
    "#     balanced_sampling=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch [1/10] - Train Loss: 10.2791 - Val Loss: 3.7059 - Train Accuracy: 0.7190 - Val Accuracy: 0.8291\n",
    "                                                                   \n",
    "Epoch [2/10] - Train Loss: 3.1310 - Val Loss: 1.9731 - Train Accuracy: 0.8250 - Val Accuracy: 0.8330\n",
    "                                                                   \n",
    "Epoch [3/10] - Train Loss: 1.9117 - Val Loss: 1.6126 - Train Accuracy: 0.8360 - Val Accuracy: 0.8395\n",
    "                                                                   \n",
    "Epoch [4/10] - Train Loss: 1.2980 - Val Loss: 1.4563 - Train Accuracy: 0.8530 - Val Accuracy: 0.8354\n",
    "                                                                   \n",
    "Epoch [5/10] - Train Loss: 0.9279 - Val Loss: 0.9853 - Train Accuracy: 0.8780 - Val Accuracy: 0.8581\n",
    "                                                                   \n",
    "Epoch [6/10] - Train Loss: 0.8566 - Val Loss: 0.5171 - Train Accuracy: 0.8880 - Val Accuracy: 0.9131\n",
    "                                                                   \n",
    "Epoch [7/10] - Train Loss: 0.6793 - Val Loss: 0.4452 - Train Accuracy: 0.9000 - Val Accuracy: 0.9159\n",
    "                                                                   \n",
    "Epoch [8/10] - Train Loss: 0.3773 - Val Loss: 0.3985 - Train Accuracy: 0.9260 - Val Accuracy: 0.9213\n",
    "                                                                   \n",
    "Epoch [9/10] - Train Loss: 0.2953 - Val Loss: 0.3818 - Train Accuracy: 0.9430 - Val Accuracy: 0.9239\n",
    "                                                                   \n",
    "Epoch [10/10] - Train Loss: 0.3581 - Val Loss: 0.3543 - Train Accuracy: 0.9140 - Val Accuracy: 0.9273\n",
    "\n",
    "Model saved to:  ..\\data\\models\\all\\TwoLayerPerceptron_b_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = get_model(\"trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Unlearned Model\n",
    "\n",
    "This model has the same training conditions as the \"Trained Model\", with the only difference being, that it had no sevens __with no middle line__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main(\n",
    "#     new_name=\"exact_model\",\n",
    "#     model=copy.deepcopy(untrained_model),\n",
    "#     sampling_mode=\"except_erased\",\n",
    "#     balanced_sampling=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch [1/10] - Train Loss: 11.0494 - Val Loss: 3.9705 - Train Accuracy: 0.6790 - Val Accuracy: 0.8060\n",
    "                                                                   \n",
    "Epoch [2/10] - Train Loss: 2.8843 - Val Loss: 2.0364 - Train Accuracy: 0.8210 - Val Accuracy: 0.8452\n",
    "                                                                   \n",
    "Epoch [3/10] - Train Loss: 1.9582 - Val Loss: 1.9326 - Train Accuracy: 0.8260 - Val Accuracy: 0.8066\n",
    "                                                                   \n",
    "Epoch [4/10] - Train Loss: 1.0714 - Val Loss: 0.6197 - Train Accuracy: 0.8630 - Val Accuracy: 0.9021\n",
    "                                                                   \n",
    "Epoch [5/10] - Train Loss: 0.9799 - Val Loss: 0.7909 - Train Accuracy: 0.8540 - Val Accuracy: 0.8872\n",
    "                                                                   \n",
    "Epoch [6/10] - Train Loss: 0.5125 - Val Loss: 0.5123 - Train Accuracy: 0.9140 - Val Accuracy: 0.9135\n",
    "                                                                   \n",
    "Epoch [7/10] - Train Loss: 0.3382 - Val Loss: 0.4401 - Train Accuracy: 0.9360 - Val Accuracy: 0.9180\n",
    "                                                                   \n",
    "Epoch [8/10] - Train Loss: 0.6186 - Val Loss: 0.3889 - Train Accuracy: 0.8990 - Val Accuracy: 0.9229\n",
    "                                                                   \n",
    "Epoch [9/10] - Train Loss: 0.4423 - Val Loss: 0.3394 - Train Accuracy: 0.9170 - Val Accuracy: 0.9277\n",
    "                                                                   \n",
    "Epoch [10/10] - Train Loss: 0.4092 - Val Loss: 0.3211 - Train Accuracy: 0.9370 - Val Accuracy: 0.9291\n",
    "\n",
    "Model saved to:  ..\\data\\models\\except_erased\\TwoLayerPerceptron_b_exact_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_model = get_model(\"exact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach.conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
